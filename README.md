# Can LLMs Replace Neil DeGrasse Tyson: Evaluating Reliability of LLMs as Science Communicators
This is the official repository for our <a href = 'https://openreview.net/forum?id=Eqpnq1sC43'> paper</a>. This work proposes a novel dataset **SCiPS-QA**, a collection of 742 boolean problems grounded in extremely complex scientific objects. We show that the dataset is a tougher benchmark than popular scientific QA datasets. We benchmark a collection of 14 open models from the Llama-3, Llama-2 and Mistral families, and proprietary models from the GPT family.<br>

## Contact and Citations
For any questions about the paper or the code, please contact the first author. If you find our code or paper useful, please cite the paper:
```
@article{bajpai2024llm_science_miscommunication ,
  title={Can LLMs Replace Neil DeGrasse Tyson: Evaluating Reliability of LLMs as Science Communicators},
  author={Prasoon Bajpai, Subhabrata Dutta, Niladri Chatterjee, Tanmoy Chakraborty},
  journal={arXiv preprint},
  year={2024}
}
```

## Content

1. [Installation](#installation)
2. [SCiPS-QA](#scipsqa)
3. [Benchmark](#benchmark)

### Installation

#### Via `requirements.txt` (using `pip`)
To install the required dependencies using pip, you can run the following command:

```bash
pip install -r requirements.txt
```

#### Via `environment.yml` (using `conda`)
To create a conda environment with the required dependencies, use the following command:

```bash
conda env create -f environment.yml
```

### SCiPS-QA
### Benchmark
