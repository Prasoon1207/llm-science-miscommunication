{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import ast\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_stochastic_responses = 20\n",
    "df = pd.DataFrame()\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_std_deviation(lst):\n",
    "    mapping = {'A': 1, 'B': 2, 'C': 3, None: 0}\n",
    "    numerical_values = []\n",
    "    for item in lst:\n",
    "        try:\n",
    "            numerical_values.append(mapping[item])\n",
    "        except KeyError:\n",
    "            numerical_values.append(0)\n",
    "    return np.std(numerical_values)\n",
    "\n",
    "def response_parser(s):\n",
    "    match = re.search(r'[A-Z]', s)\n",
    "    if match:\n",
    "        if(match.group(0) not in ['A', 'B', 'C']):\n",
    "            return None\n",
    "        return match.group(0)\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def get_most_frequent_value(arr):\n",
    "    counter = Counter(arr)\n",
    "    try:\n",
    "        most_frequent_value, _ = counter.most_common(1)[0]\n",
    "    except:\n",
    "        most_frequent_value = None\n",
    "    return most_frequent_value  \n",
    "\n",
    "def get_most_frequent_non_none_value(arr):\n",
    "    filtered_arr = [x for x in arr if x is not None]\n",
    "    counter = Counter(filtered_arr)\n",
    "    \n",
    "    try:\n",
    "        most_common_value, _ = counter.most_common(1)[0]\n",
    "    except:\n",
    "        most_common_value = None # case when all values in arr are nan\n",
    "    return most_common_value\n",
    "\n",
    "\n",
    "def get_accuracy(pred, true):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pred (list): list of lists of stochastic responses\n",
    "        true (list): list of lists of stochastic responses\n",
    "\n",
    "    Returns:\n",
    "        (float) : exact match accuracy\n",
    "    \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for x, y in zip(pred, true):\n",
    "        if(x == y): count += 1\n",
    "    return count / len(pred)\n",
    "\n",
    "\n",
    "def get_accuracy_none(pred, true):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pred (list): list of lists of stochastic responses\n",
    "        true (list): list of lists of stochastic responses\n",
    "\n",
    "    Returns:\n",
    "        (float) : exact match accuracy\n",
    "    \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for x, y in zip(pred, true):\n",
    "        if(x == None and y == None):\n",
    "            continue\n",
    "        if(x == y): count += 1\n",
    "    return count / len(pred)\n",
    "\n",
    "\n",
    "def get_major_stochastic_response(stochastic_response, consider_nan = False):\n",
    "    major_stochastic_response = []\n",
    "    for arr in stochastic_response:\n",
    "        if(consider_nan):\n",
    "            try:\n",
    "                major_stochastic_response.append(get_most_frequent_value(list(ast.literal_eval(arr))))\n",
    "            except:\n",
    "                major_stochastic_response.append(get_most_frequent_value(arr))\n",
    "            continue\n",
    "        major_stochastic_response.append(get_most_frequent_non_none_value(list(ast.literal_eval(arr))))\n",
    "        \n",
    "    return major_stochastic_response\n",
    "\n",
    "def get_none_value_perc(arr):\n",
    "    s = 0\n",
    "    for elem in arr:\n",
    "        if(elem is None): s += 1\n",
    "    return s / len(arr)\n",
    "\n",
    "def get_none_value_from_response(stochastic_response):\n",
    "    none_perc_response = []\n",
    "    for arr in stochastic_response:\n",
    "        none_perc_response.append(get_none_value_perc(list(ast.literal_eval(arr))))\n",
    "    return none_perc_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 742/742 [00:00<00:00, 19581.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 742/742 [00:00<00:00, 23994.62it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 25951.22it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 11373.12it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 15840.69it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 28258.32it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 28530.33it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 28839.92it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 32913.90it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 28502.89it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 24971.10it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 18106.66it/s]\n",
      "100%|██████████| 742/742 [00:00<00:00, 17922.11it/s]\n"
     ]
    }
   ],
   "source": [
    "output_directory = '/home/prasoon/snap/main/mtp/llm-science-miscommunication/results/open'\n",
    "for model_file in os.listdir(output_directory):\n",
    "    models.append(model_file[:-4])\n",
    "    with open(output_directory + '/' + model_file, 'rb') as f:\n",
    "        result = pickle.load(f)\n",
    "    model_main = []\n",
    "    model_stochastic = []\n",
    "\n",
    "    for index in tqdm(range(len(result))):\n",
    "        response = result[index]\n",
    "        main_response = response_parser(response['main']['generated_text'])\n",
    "        model_main.append(main_response)\n",
    "        stochastic_responses = []\n",
    "        for stochastic_index in range(number_of_stochastic_responses):\n",
    "            stochastic_responses.append(response_parser(response['stochastic_'+str(stochastic_index)]['generated_text']))\n",
    "        model_stochastic.append(stochastic_responses)\n",
    "    df[model_file[:-4] + '_main'] = model_main\n",
    "    df[model_file[:-4] + '_stochastic'] = model_stochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/prasoon/snap/main/mtp/llm-science-miscommunication/data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "subject_wise_results = {'physics': {}, 'mathematics': {}, 'chemistry': {}, 'theoretical_cs': {}}\n",
    "\n",
    "# target keys <- information\n",
    "keys = [    'main_response_accuracy', \n",
    "            'major_stochastic_response_accuracy',\n",
    "            'mean_variance_stochastic_response',\n",
    "            'open_answer_abstinence',\n",
    "            'closed_main_response_accuracy',\n",
    "            'closed_major_stochastic_response_accuracy',\n",
    "            'main_response_stochastic_response_agreeability',\n",
    "            'main_response_stochastic_response_agreeability_without_none']\n",
    "\n",
    "closed_answer_index = data.index[data['answer'] != 'C'].tolist()\n",
    "open_answer_index = data.index[data['answer'] == 'C'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model_results[model] = {}\n",
    "    # collecting the main_response and replacing nan with None\n",
    "    # .... to check the agreeability of the main response and major stochastic responses\n",
    "    main_response = list(df[model + '_main'])\n",
    "    for index in range(len(main_response)):\n",
    "        try:\n",
    "            if(math.isnan(main_response[index])):\n",
    "                main_response[index] = None\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # collecting the major stochastic responses\n",
    "    #.... considering nan values as value entries and replacing wherever they are major to 'None'\n",
    "    \n",
    "    stochastic_response = list(df[model + '_stochastic'])\n",
    "    major_stochastic_response = get_major_stochastic_response(stochastic_response, consider_nan = True) \n",
    "    # getting 'main_response_accuracy' & 'stochastic_response_accuracy'\n",
    "    main_response_accuracy = get_accuracy(main_response, data['answer'])\n",
    "    major_stochastic_response_accuracy = get_accuracy(major_stochastic_response, data['answer'])\n",
    "        \n",
    "    # getting 'agreeability' of the main_response and stochastic_response\n",
    "    main_response_stochastic_response_agreeability = get_accuracy(main_response, major_stochastic_response)\n",
    "    main_response_stochastic_response_agreeability_without_none = get_accuracy_none(main_response, major_stochastic_response)\n",
    "    # here we are discounting those cases where both main_response and major_stochastic_response is none\n",
    "    # we are treating them as mismatch\n",
    "    \n",
    "    closed_main_response = [main_response[index] for index in closed_answer_index]\n",
    "    closed_major_stochastic_response = [major_stochastic_response[index] for index in closed_answer_index]  \n",
    "    closed_true_answers = [list(data['answer'])[index] for index in closed_answer_index]\n",
    "    \n",
    "    closed_main_response_accuracy = get_accuracy(closed_main_response, closed_true_answers)\n",
    "    closed_major_stochastic_response_accuracy = get_accuracy(closed_major_stochastic_response, closed_true_answers)\n",
    "    \n",
    "    open_main_response = [main_response[index] for index in open_answer_index]\n",
    "    open_major_stochastic_response = [major_stochastic_response[index] for index in open_answer_index]\n",
    "    open_true_answers = [list(data['answer'])[index] for index in open_answer_index]\n",
    "    \n",
    "    open_main_response_accuracy = get_accuracy(open_main_response, open_true_answers)\n",
    "    open_major_stochastic_response_accuracy = get_accuracy(open_major_stochastic_response, open_true_answers)\n",
    "    \n",
    "    \n",
    "    variance_stochastic_response = []\n",
    "    for arr in stochastic_response:\n",
    "        try:\n",
    "            variance_stochastic_response.append(calculate_std_deviation(ast.literal_eval(arr)))\n",
    "        except:\n",
    "            variance_stochastic_response.append(calculate_std_deviation(arr))\n",
    "        \n",
    "    mean_variance_stochastic_response = np.mean(variance_stochastic_response)\n",
    "    \n",
    "    \n",
    "    model_results[model]['mean_variance_stochastic_response'] = mean_variance_stochastic_response\n",
    "    model_results[model]['main_response_accuracy'] = main_response_accuracy\n",
    "    model_results[model]['major_stochastic_response_accuracy'] = major_stochastic_response_accuracy\n",
    "    model_results[model]['main_response_stochastic_response_agreeability'] = main_response_stochastic_response_agreeability\n",
    "    model_results[model]['main_response_stochastic_response_agreeability_without_none'] = main_response_stochastic_response_agreeability_without_none\n",
    "    model_results[model]['closed_main_response_accuracy'] = closed_main_response_accuracy\n",
    "    model_results[model]['closed_major_stochastic_response_accuracy'] = closed_major_stochastic_response_accuracy\n",
    "    model_results[model]['open_main_response_accuracy'] = open_main_response_accuracy\n",
    "    model_results[model]['open_major_stochastic_response_accuracy'] = open_major_stochastic_response_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama-3-70b-instruct\n",
      "{'mean_variance_stochastic_response': 0.2947699876330266, 'main_response_accuracy': 0.628032345013477, 'major_stochastic_response_accuracy': 0.6226415094339622, 'main_response_stochastic_response_agreeability': 0.9663072776280324, 'main_response_stochastic_response_agreeability_without_none': 0.9582210242587601, 'closed_main_response_accuracy': 0.7803921568627451, 'closed_major_stochastic_response_accuracy': 0.7843137254901961, 'open_main_response_accuracy': 0.29310344827586204, 'open_major_stochastic_response_accuracy': 0.2672413793103448}\n",
      "----------------\n",
      "llama-2-13b-hf\n",
      "{'mean_variance_stochastic_response': 0.8262193593294048, 'main_response_accuracy': 0.3274932614555256, 'major_stochastic_response_accuracy': 0.3611859838274933, 'main_response_stochastic_response_agreeability': 0.5431266846361186, 'main_response_stochastic_response_agreeability_without_none': 0.5363881401617251, 'closed_main_response_accuracy': 0.4764705882352941, 'closed_major_stochastic_response_accuracy': 0.5235294117647059, 'open_main_response_accuracy': 0.0, 'open_major_stochastic_response_accuracy': 0.004310344827586207}\n",
      "----------------\n",
      "meta-llama-3-70b\n",
      "{'mean_variance_stochastic_response': 0.9643469971787497, 'main_response_accuracy': 0.692722371967655, 'major_stochastic_response_accuracy': 0.605121293800539, 'main_response_stochastic_response_agreeability': 0.77088948787062, 'main_response_stochastic_response_agreeability_without_none': 0.7601078167115903, 'closed_main_response_accuracy': 0.7431372549019608, 'closed_major_stochastic_response_accuracy': 0.6588235294117647, 'open_main_response_accuracy': 0.5818965517241379, 'open_major_stochastic_response_accuracy': 0.4870689655172414}\n",
      "----------------\n",
      "llama-2-7b-chat-hf\n",
      "{'mean_variance_stochastic_response': 1.0691843863551271, 'main_response_accuracy': 0.32075471698113206, 'major_stochastic_response_accuracy': 0.2722371967654987, 'main_response_stochastic_response_agreeability': 0.7641509433962265, 'main_response_stochastic_response_agreeability_without_none': 0.7088948787061995, 'closed_main_response_accuracy': 0.28431372549019607, 'closed_major_stochastic_response_accuracy': 0.2549019607843137, 'open_main_response_accuracy': 0.40086206896551724, 'open_major_stochastic_response_accuracy': 0.3103448275862069}\n",
      "----------------\n",
      "mixtral-8x7b-instruct-v0.1\n",
      "{'mean_variance_stochastic_response': 0.5546325630386082, 'main_response_accuracy': 0.5916442048517521, 'major_stochastic_response_accuracy': 0.5956873315363881, 'main_response_stochastic_response_agreeability': 0.9420485175202157, 'main_response_stochastic_response_agreeability_without_none': 0.9164420485175202, 'closed_main_response_accuracy': 0.6784313725490196, 'closed_major_stochastic_response_accuracy': 0.6823529411764706, 'open_main_response_accuracy': 0.40086206896551724, 'open_major_stochastic_response_accuracy': 0.4051724137931034}\n",
      "----------------\n",
      "llama-2-70b-hf\n",
      "{'mean_variance_stochastic_response': 1.096743735878857, 'main_response_accuracy': 0.532345013477089, 'major_stochastic_response_accuracy': 0.27358490566037735, 'main_response_stochastic_response_agreeability': 0.48247978436657685, 'main_response_stochastic_response_agreeability_without_none': 0.34097035040431267, 'closed_main_response_accuracy': 0.4980392156862745, 'closed_major_stochastic_response_accuracy': 0.29215686274509806, 'open_main_response_accuracy': 0.6077586206896551, 'open_major_stochastic_response_accuracy': 0.23275862068965517}\n",
      "----------------\n",
      "meta-llama-3-8b-instruct\n",
      "{'mean_variance_stochastic_response': 0.5504826408096781, 'main_response_accuracy': 0.444743935309973, 'major_stochastic_response_accuracy': 0.4366576819407008, 'main_response_stochastic_response_agreeability': 0.9433962264150944, 'main_response_stochastic_response_agreeability_without_none': 0.9407008086253369, 'closed_main_response_accuracy': 0.6450980392156863, 'closed_major_stochastic_response_accuracy': 0.6352941176470588, 'open_main_response_accuracy': 0.004310344827586207, 'open_major_stochastic_response_accuracy': 0.0}\n",
      "----------------\n",
      "meta-llama-3-8b\n",
      "{'mean_variance_stochastic_response': 1.014482775548788, 'main_response_accuracy': 0.11994609164420485, 'major_stochastic_response_accuracy': 0.09703504043126684, 'main_response_stochastic_response_agreeability': 0.761455525606469, 'main_response_stochastic_response_agreeability_without_none': 0.10377358490566038, 'closed_main_response_accuracy': 0.17450980392156862, 'closed_major_stochastic_response_accuracy': 0.1392156862745098, 'open_main_response_accuracy': 0.0, 'open_major_stochastic_response_accuracy': 0.004310344827586207}\n",
      "----------------\n",
      "mistral-7b-instruct-v0.1\n",
      "{'mean_variance_stochastic_response': 0.6599335580811804, 'main_response_accuracy': 0.11320754716981132, 'major_stochastic_response_accuracy': 0.3113207547169811, 'main_response_stochastic_response_agreeability': 0.5862533692722371, 'main_response_stochastic_response_agreeability_without_none': 0.1347708894878706, 'closed_main_response_accuracy': 0.16470588235294117, 'closed_major_stochastic_response_accuracy': 0.45294117647058824, 'open_main_response_accuracy': 0.0, 'open_major_stochastic_response_accuracy': 0.0}\n",
      "----------------\n",
      "llama-2-7b-hf\n",
      "{'mean_variance_stochastic_response': 0.9216512145187917, 'main_response_accuracy': 0.0215633423180593, 'major_stochastic_response_accuracy': 0.1078167115902965, 'main_response_stochastic_response_agreeability': 0.7776280323450134, 'main_response_stochastic_response_agreeability_without_none': 0.02021563342318059, 'closed_main_response_accuracy': 0.03137254901960784, 'closed_major_stochastic_response_accuracy': 0.1568627450980392, 'open_main_response_accuracy': 0.0, 'open_major_stochastic_response_accuracy': 0.0}\n",
      "----------------\n",
      "llama-2-13b-chat-hf\n",
      "{'mean_variance_stochastic_response': 0.6364200679400017, 'main_response_accuracy': 0.34097035040431267, 'major_stochastic_response_accuracy': 0.3557951482479784, 'main_response_stochastic_response_agreeability': 0.8881401617250674, 'main_response_stochastic_response_agreeability_without_none': 0.8477088948787062, 'closed_main_response_accuracy': 0.4843137254901961, 'closed_major_stochastic_response_accuracy': 0.5, 'open_main_response_accuracy': 0.02586206896551724, 'open_major_stochastic_response_accuracy': 0.03879310344827586}\n",
      "----------------\n",
      "mistral-7b-instruct-v0.2\n",
      "{'mean_variance_stochastic_response': 0.474484374522358, 'main_response_accuracy': 0.49595687331536387, 'major_stochastic_response_accuracy': 0.48787061994609165, 'main_response_stochastic_response_agreeability': 0.9326145552560647, 'main_response_stochastic_response_agreeability_without_none': 0.8557951482479784, 'closed_main_response_accuracy': 0.5823529411764706, 'closed_major_stochastic_response_accuracy': 0.5745098039215686, 'open_main_response_accuracy': 0.30603448275862066, 'open_major_stochastic_response_accuracy': 0.2974137931034483}\n",
      "----------------\n",
      "llama-2-70b-chat-hf\n",
      "{'mean_variance_stochastic_response': 0.6887990705135897, 'main_response_accuracy': 0.42318059299191374, 'major_stochastic_response_accuracy': 0.42587601078167114, 'main_response_stochastic_response_agreeability': 0.8908355795148248, 'main_response_stochastic_response_agreeability_without_none': 0.8733153638814016, 'closed_main_response_accuracy': 0.615686274509804, 'closed_major_stochastic_response_accuracy': 0.6196078431372549, 'open_main_response_accuracy': 0.0, 'open_major_stochastic_response_accuracy': 0.0}\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for model in list(model_results.keys()):\n",
    "    print(model)\n",
    "    print(model_results[model])\n",
    "    print('----------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
